{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7tCNFEwfxqpLpNCeiUZLm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byron-Leung/Deep-learning/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEXg0kIZhs0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "10683318-6e56-4e04-efbf-5bd18347d138"
      },
      "source": [
        "#this part mount google drive to colab\n",
        "import os\n",
        "import tarfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtE-gBidahay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls /content/gdrive/My drive/dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xDRbasQjR7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = 'gdrive/My Drive/dataset/train'\n",
        "test_dir = 'gdrive/My Drive/dataset/test'\n",
        "vali_dir = 'gdrive/My Drive/dataset/val'\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45\n",
        "                                 ,width_shift_range=0.2\n",
        "                                 ,height_shift_range=0.2,shear_range=0.2\n",
        "\n",
        "                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20\n",
        "                                                  ,class_mode=\"sparse\")#return 2D one-hot label\n",
        "validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")\n",
        "test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAejTpIUa4Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYIz9hTPbZir",
        "colab_type": "text"
      },
      "source": [
        "resnet50\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB9qqeG3bV8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = 'gdrive/My Drive/dataset/train'\n",
        "test_dir = 'gdrive/My Drive/dataset/test'\n",
        "vali_dir = 'gdrive/My Drive/dataset/val'\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45\n",
        "                                 ,width_shift_range=0.2\n",
        "                                 ,height_shift_range=0.2,shear_range=0.2\n",
        "\n",
        "                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=20\n",
        "                                                  ,class_mode=\"sparse\")#return 2D one-hot label\n",
        "validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(224,224),batch_size=20,class_mode=\"sparse\")\n",
        "test_generator=test_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=20,class_mode=\"sparse\")\n",
        "from keras.applications.resnet50 import resnet50\n",
        "resnetmodel = keras.applications.resnet.ResNet50(include_top=True, weights='imagenet'\n",
        "                                   , input_tensor=None, input_shape=None #default shape(224,224)\n",
        "                                   , pooling='avg')\n",
        "                                                 # , classes=120)\n",
        "resnetmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.RMSprop(lr=0.1),metrics=['accuracy'])\n",
        "reshistory = resnetmodel.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44xumAxbk37",
        "colab_type": "text"
      },
      "source": [
        "Vgg16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_wbubEpbmt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import vgg16\n",
        "vggmodel = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n",
        "                                input_tensor=None, input_shape=None,\n",
        "                                pooling=None,\n",
        "                                classes=1000)\n",
        "vggmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.RMSprop(lr=0.1),metrics=['accuracy'])\n",
        "vggmodel.summary()\n",
        "vgghistory = vggmodel.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzAk5XEZ9KUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12MPhbCKbsMy",
        "colab_type": "text"
      },
      "source": [
        "xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYx02VJsbvXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5eb39230-dc45-4fba-fbf2-28ae7434b200"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "train_dir = 'gdrive/My Drive/dataset/train'\n",
        "test_dir = 'gdrive/My Drive/dataset/test'\n",
        "vali_dir = 'gdrive/My Drive/dataset/val'\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45\n",
        "                                 ,width_shift_range=0.2\n",
        "                                 ,height_shift_range=0.2,shear_range=0.2\n",
        "                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20\n",
        "                                                  ,class_mode=\"sparse\")#return 2D one-hot label\n",
        "validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")\n",
        "test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")\n",
        "from keras.applications.xception import xception\n",
        "xmodel = keras.applications.xception.Xception(include_top=True, weights='imagenet'\n",
        "                                              , input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
        "##%\n",
        "xmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])\n",
        "#%%\n",
        "xhistory = xmodel.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16418 images belonging to 120 classes.\n",
            "Found 2009 images belonging to 120 classes.\n",
            "Found 16418 images belonging to 120 classes.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "91889664/91884032 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}