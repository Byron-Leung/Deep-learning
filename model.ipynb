{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaP5MQipCW4oVVFSaDoCa1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byron-Leung/Deep-learning/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEXg0kIZhs0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e5ecc15b-87a4-4ae6-cd6a-80dac84bedca"
      },
      "source": [
        "#this part mount google drive to colab\n",
        "import os\n",
        "import tarfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xDRbasQjR7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = 'gdrive/My Drive/dataset/train'\n",
        "test_dir = 'gdrive/My Drive/dataset/test'\n",
        "vali_dir = 'gdrive/My Drive/dataset/val'\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45\n",
        "                                 ,width_shift_range=0.2\n",
        "                                 ,height_shift_range=0.2,shear_range=0.2\n",
        "\n",
        "                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20\n",
        "                                                  ,class_mode=\"sparse\")#return 2D one-hot label\n",
        "validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")\n",
        "test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAejTpIUa4Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYIz9hTPbZir",
        "colab_type": "text"
      },
      "source": [
        "resnet50\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB9qqeG3bV8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7e1d0f60-a2f2-4318-a485-fc55b95f065d"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = 'gdrive/My Drive/dataset/train'\n",
        "test_dir = 'gdrive/My Drive/dataset/test'\n",
        "vali_dir = 'gdrive/My Drive/dataset/val'\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45\n",
        "                                 ,width_shift_range=0.2\n",
        "                                 ,height_shift_range=0.2,shear_range=0.2\n",
        "\n",
        "                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=20\n",
        "                                                  ,class_mode=\"sparse\")#return 2D one-hot label\n",
        "validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(224,224),batch_size=20,class_mode=\"sparse\")\n",
        "test_generator=test_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=20,class_mode=\"sparse\")\n",
        "from keras.applications.resnet50 import resnet50\n",
        "resnetmodel = keras.applications.resnet.ResNet50(include_top=True, weights='imagenet'\n",
        "                                   , input_tensor=None, input_shape=None #default shape(224,224)\n",
        "                                   , pooling='avg')\n",
        "                                                 # , classes=120)\n",
        "resnetmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])\n",
        "reshistory = resnetmodel.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=None)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16418 images belonging to 120 classes.\n",
            "Found 2009 images belonging to 120 classes.\n",
            "Found 16418 images belonging to 120 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-53d428461a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m resnetmodel = keras.applications.resnet.ResNet50(include_top=True, weights='imagenet'\n\u001b[0m\u001b[1;32m     18\u001b[0m                                    \u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;31m#default shape(224,224)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                    , pooling='avg')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44xumAxbk37",
        "colab_type": "text"
      },
      "source": [
        "Vgg16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_wbubEpbmt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a3305145-4951-4b1b-caf0-42cdc8c57ed7"
      },
      "source": [
        "from keras.applications.vgg16 import vgg16\n",
        "vggmodel = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n",
        "                                input_tensor=None, input_shape=None,\n",
        "                                pooling=None,\n",
        "                                classes=1000)\n",
        "vggmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])\n",
        "vggmodel.summary()\n",
        "vgghistory = vggmodel.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=None)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f1a82929c182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m vggmodel = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n\u001b[0m\u001b[1;32m      3\u001b[0m                                 \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 classes=1000)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzAk5XEZ9KUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12MPhbCKbsMy",
        "colab_type": "text"
      },
      "source": [
        "xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYx02VJsbvXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5eb39230-dc45-4fba-fbf2-28ae7434b200"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "train_dir = 'gdrive/My Drive/dataset/train'\n",
        "test_dir = 'gdrive/My Drive/dataset/test'\n",
        "vali_dir = 'gdrive/My Drive/dataset/val'\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45\n",
        "                                 ,width_shift_range=0.2\n",
        "                                 ,height_shift_range=0.2,shear_range=0.2\n",
        "                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode=\"nearest\")\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20\n",
        "                                                  ,class_mode=\"sparse\")#return 2D one-hot label\n",
        "validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")\n",
        "test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode=\"sparse\")\n",
        "from keras.applications.xception import xception\n",
        "xmodel = keras.applications.xception.Xception(include_top=True, weights='imagenet'\n",
        "                                              , input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
        "##%\n",
        "xmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])\n",
        "#%%\n",
        "xhistory = xmodel.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=None,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=None)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16418 images belonging to 120 classes.\n",
            "Found 2009 images belonging to 120 classes.\n",
            "Found 16418 images belonging to 120 classes.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "91889664/91884032 [==============================] - 3s 0us/step\n",
            "Epoch 1/30\n",
            "733/821 [=========================>....] - ETA: 8:38 - loss: 5.1245 - accuracy: 0.0653"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 566 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "821/821 [==============================] - 5398s 7s/step - loss: 4.9433 - accuracy: 0.0836 - val_loss: 2.3631 - val_accuracy: 0.3614\n",
            "Epoch 2/30\n",
            "821/821 [==============================] - 559s 681ms/step - loss: 2.3412 - accuracy: 0.4556 - val_loss: 1.4981 - val_accuracy: 0.7312\n",
            "Epoch 3/30\n",
            "821/821 [==============================] - 561s 683ms/step - loss: 1.4842 - accuracy: 0.6116 - val_loss: 0.4932 - val_accuracy: 0.7924\n",
            "Epoch 4/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 1.1710 - accuracy: 0.6785 - val_loss: 0.9982 - val_accuracy: 0.8173\n",
            "Epoch 5/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.9911 - accuracy: 0.7173 - val_loss: 0.1398 - val_accuracy: 0.8288\n",
            "Epoch 6/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.8813 - accuracy: 0.7436 - val_loss: 0.1886 - val_accuracy: 0.8347\n",
            "Epoch 7/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.7831 - accuracy: 0.7692 - val_loss: 0.4917 - val_accuracy: 0.8477\n",
            "Epoch 8/30\n",
            "821/821 [==============================] - 556s 678ms/step - loss: 0.7033 - accuracy: 0.7930 - val_loss: 0.2936 - val_accuracy: 0.8427\n",
            "Epoch 9/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.6558 - accuracy: 0.8024 - val_loss: 1.0316 - val_accuracy: 0.8556\n",
            "Epoch 10/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.5969 - accuracy: 0.8218 - val_loss: 0.5040 - val_accuracy: 0.8412\n",
            "Epoch 11/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.5629 - accuracy: 0.8283 - val_loss: 0.5722 - val_accuracy: 0.8547\n",
            "Epoch 12/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.5208 - accuracy: 0.8438 - val_loss: 0.2446 - val_accuracy: 0.8387\n",
            "Epoch 13/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.4750 - accuracy: 0.8567 - val_loss: 0.1367 - val_accuracy: 0.8497\n",
            "Epoch 14/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.4515 - accuracy: 0.8578 - val_loss: 0.0867 - val_accuracy: 0.8517\n",
            "Epoch 15/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.4292 - accuracy: 0.8697 - val_loss: 0.1040 - val_accuracy: 0.8477\n",
            "Epoch 16/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.3980 - accuracy: 0.8794 - val_loss: 0.5555 - val_accuracy: 0.8601\n",
            "Epoch 17/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 0.3781 - accuracy: 0.8839 - val_loss: 0.2420 - val_accuracy: 0.8522\n",
            "Epoch 18/30\n",
            "821/821 [==============================] - 557s 678ms/step - loss: 0.3499 - accuracy: 0.8939 - val_loss: 0.6324 - val_accuracy: 0.8437\n",
            "Epoch 19/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.3316 - accuracy: 0.8963 - val_loss: 0.2356 - val_accuracy: 0.8517\n",
            "Epoch 20/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.3134 - accuracy: 0.9066 - val_loss: 1.5348 - val_accuracy: 0.8522\n",
            "Epoch 21/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 0.2971 - accuracy: 0.9106 - val_loss: 0.5298 - val_accuracy: 0.8492\n",
            "Epoch 22/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 0.2814 - accuracy: 0.9133 - val_loss: 0.5362 - val_accuracy: 0.8442\n",
            "Epoch 23/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 0.2626 - accuracy: 0.9203 - val_loss: 0.8951 - val_accuracy: 0.8462\n",
            "Epoch 24/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 0.2433 - accuracy: 0.9259 - val_loss: 0.2183 - val_accuracy: 0.8462\n",
            "Epoch 25/30\n",
            "821/821 [==============================] - 558s 679ms/step - loss: 0.2392 - accuracy: 0.9282 - val_loss: 0.0770 - val_accuracy: 0.8407\n",
            "Epoch 26/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.2275 - accuracy: 0.9314 - val_loss: 1.3263 - val_accuracy: 0.8452\n",
            "Epoch 27/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.2114 - accuracy: 0.9357 - val_loss: 0.7149 - val_accuracy: 0.8462\n",
            "Epoch 28/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.2043 - accuracy: 0.9397 - val_loss: 0.4498 - val_accuracy: 0.8452\n",
            "Epoch 29/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.1975 - accuracy: 0.9407 - val_loss: 0.3145 - val_accuracy: 0.8447\n",
            "Epoch 30/30\n",
            "821/821 [==============================] - 557s 679ms/step - loss: 0.1894 - accuracy: 0.9455 - val_loss: 0.9866 - val_accuracy: 0.8472\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}